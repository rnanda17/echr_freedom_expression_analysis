{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e95e8a-3f28-4584-b523-4d1f794058a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e210c6ba-1c1c-4c1e-b002-274076a1ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "Extracted Text from: hate speech factsheet - facts.docx\n",
      "========================================\n",
      "Hate speech\n",
      "Threat to the democratic order\n",
      "As a rule, the Court will declare inadmissible, on grounds of incompatibility with the values of the Convention, applications which are inspired by totalitarian doctrine or which express ideas that represent a threat to the democratic order and are liable to lead to the restoration of a totalitarian regime.\n",
      "Racial hate\n",
      "Glimmerveen and Haqenbeek v. the Netherlands \n",
      "11 October 1979 (decision of the European Commission of Human Rights4) \n",
      "In this case, the applicants had been convicted for possessing leaflets addressed to “White Dutch people”, which tended to make sure notably that everyone who was not white left the Netherlands.\n",
      "Negationism and revisionism\n",
      "Garaudy v. France \n",
      "24 June 2003 (decision on the admissibility) \n",
      "The applicant, the author of a book entitled The Founding Myths of Modern Israel, was convicted of the offences of disputing the existence of crimes against humanity, defamation in public of a group of persons – in this case, the \n",
      "... (truncated, total 33261 characters)\n",
      "========================================\n",
      "\n",
      "========================================\n",
      "Extracted Text from: access to internet factsheet - facts.docx\n",
      "========================================\n",
      "Access to Internet and freedom to receive and impart information and ideas\n",
      "Measures blocking access to Internet \n",
      "Ahmet Yıldırım v. Turkey \n",
      "18 December 2012 (judgment) \n",
      "This case concerned a court decision to block access to Google Sites, which hosted an Internet site whose owner was facing criminal proceedings for insulting the memory of Atatürk. As a result of the decision, access to all other sites hosted by the service was blocked. The applicant complained that he was unable to access his own Internet site because of this measure ordered in the context of criminal proceedings without any connection to him or his site. He submitted that the measure infringed his right to freedom to receive and impart information and ideas.\n",
      "Akdeniz v. Turkey \n",
      "11 March 2014 (decision on the admissibility) \n",
      "This case concerned the blocking of access to two websites (“myspace.com” and “last.fm”) on the grounds that they streamed music without respecting copyright legislation. As a regular user of the web\n",
      "... (truncated, total 5969 characters)\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_docx_files(docx_folder_path):\n",
    "    \"\"\"Extract text from all valid DOCX files in a folder.\"\"\"\n",
    "    documents_with_names = []\n",
    "    for file in os.listdir(docx_folder_path):\n",
    "        # Exclude temporary or invalid files\n",
    "        if file.endswith('.docx') and not file.startswith('~$'):\n",
    "            docx_path = os.path.join(docx_folder_path, file)\n",
    "            document = Document(docx_path)\n",
    "            text = \"\\n\".join([paragraph.text for paragraph in document.paragraphs])  # Join all paragraphs\n",
    "            documents_with_names.append((file, text))  # Append as tuple (file_name, text)\n",
    "    return documents_with_names\n",
    "\n",
    "# Provide the folder containing your DOCX files\n",
    "docx_folder_path = \"/Users/rohanpersonal/git_projs/echr_freedom_expression_analysis/word_docs_facts/\"\n",
    "documents_with_names = extract_text_from_docx_files(docx_folder_path)\n",
    "\n",
    "# Display the text extracted from each document\n",
    "for file_name, text in documents_with_names:\n",
    "    print(f\"\\n{'='*40}\\nExtracted Text from: {file_name}\\n{'='*40}\")\n",
    "    print(text[:1000])  # Print the first 1000 characters for readability\n",
    "    print(f\"... (truncated, total {len(text)} characters)\\n{'='*40}\")\n",
    "\n",
    "# Separate the text content for further analysis\n",
    "documents = [text for _, text in documents_with_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74b782c-11f8-4458-8275-6a2d883d33ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohanpersonal/anaconda3/envs/freedom_expression/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keyphrases for hate speech factsheet - facts.docx:\n",
      "- netherlands negationism (Score: 0.54)\n",
      "- discrimination hatred (Score: 0.50)\n",
      "- hatred jersild (Score: 0.48)\n",
      "- condemning the (Score: 0.47)\n",
      "- inciting discrimination (Score: 0.46)\n",
      "- discrimination incitement (Score: 0.45)\n",
      "- condemning (Score: 0.45)\n",
      "- humanity defamation (Score: 0.45)\n",
      "- defamation (Score: 0.45)\n",
      "- inciting hatred (Score: 0.45)\n",
      "- hatred incitement (Score: 0.45)\n",
      "- defamation in (Score: 0.45)\n",
      "- incited hatred (Score: 0.44)\n",
      "- ethnic hatred (Score: 0.44)\n",
      "- slander against (Score: 0.43)\n",
      "- violated zemmour (Score: 0.43)\n",
      "- discrimination against (Score: 0.43)\n",
      "- racial hatred (Score: 0.42)\n",
      "- extremism legislation (Score: 0.42)\n",
      "- the holocaust (Score: 0.42)\n",
      "- germans extremism (Score: 0.42)\n",
      "- hatred among (Score: 0.42)\n",
      "- extremism on (Score: 0.42)\n",
      "- vehemently condemning (Score: 0.42)\n",
      "- disseminating extremist (Score: 0.41)\n",
      "- provoking enmity (Score: 0.41)\n",
      "- hatred violence (Score: 0.41)\n",
      "- national hatred (Score: 0.41)\n",
      "- were extremist (Score: 0.40)\n",
      "- discrimination (Score: 0.40)\n",
      "- racial discrimination (Score: 0.40)\n",
      "- hate glimmerveen (Score: 0.40)\n",
      "- the admissibility (Score: 0.40)\n",
      "- hatred after (Score: 0.40)\n",
      "- to extremism (Score: 0.40)\n",
      "\n",
      "Keyphrases for access to internet factsheet - facts.docx:\n",
      "- website restrictions (Score: 0.54)\n",
      "- turkish law (Score: 0.52)\n",
      "- against websites (Score: 0.52)\n",
      "- blocking access (Score: 0.43)\n",
      "- turkish constitutional (Score: 0.43)\n",
      "- legal ban (Score: 0.42)\n",
      "- block access (Score: 0.40)\n",
      "- certain internet (Score: 0.39)\n",
      "- banning of (Score: 0.39)\n",
      "- internet access (Score: 0.39)\n",
      "- website complained (Score: 0.38)\n",
      "- sites internet (Score: 0.37)\n",
      "- website enabling (Score: 0.37)\n",
      "- infringement of (Score: 0.37)\n",
      "- internet ahmet (Score: 0.37)\n",
      "- ahmet yıldırım (Score: 0.37)\n",
      "- yıldırım turkey (Score: 0.36)\n",
      "- website amounted (Score: 0.36)\n",
      "- refused access (Score: 0.36)\n",
      "- the banning (Score: 0.35)\n",
      "- akdeniz turkey (Score: 0.35)\n",
      "- of websites (Score: 0.35)\n",
      "- respecting copyright (Score: 0.35)\n",
      "- ban under (Score: 0.35)\n",
      "- internet sites (Score: 0.35)\n",
      "- an infringement (Score: 0.35)\n",
      "- wholesale blocking (Score: 0.35)\n",
      "- infringement (Score: 0.34)\n",
      "- banning (Score: 0.34)\n",
      "- the ban (Score: 0.34)\n",
      "- to block (Score: 0.34)\n",
      "- ban on (Score: 0.34)\n",
      "- restrictions placed (Score: 0.34)\n",
      "- websites containing (Score: 0.34)\n",
      "- internet site (Score: 0.34)\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# Initialize KeyBERT model\n",
    "kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "\n",
    "individual_keywords = []\n",
    "for file_name, doc in documents_with_names:\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        doc,\n",
    "        keyphrase_ngram_range=(1, 2),  # Allow unigrams to trigrams\n",
    "        top_n=35,                      # Extract top 35 keyphrases\n",
    "        stop_words=None                # Use default stop words or specify your own\n",
    "    )\n",
    "    individual_keywords.append((file_name, keywords))  # Use real file names\n",
    "\n",
    "# Display results\n",
    "for file_name, keywords in individual_keywords:\n",
    "    print(f\"\\nKeyphrases for {file_name}:\")\n",
    "    for phrase, score in keywords:\n",
    "        print(f\"- {phrase} (Score: {score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d47458e5-d6b3-4981-a3cc-506ce312832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Keyphrases for hate speech factsheet - facts.docx:\n",
      "- political party front national (Score: 0.0185)\n",
      "- national courts (Score: 0.0132)\n",
      "- youth human rights group v. russia10 (Score: 0.0128)\n",
      "- daily newspaper ülkede özgür gündem (Score: 0.0128)\n",
      "- left-wing basque separatist parliamentary group (Score: 0.0128)\n",
      "- terrorist group action directe (Score: 0.0125)\n",
      "- british national party (Score: 0.0122)\n",
      "- national court decisions (Score: 0.0121)\n",
      "- daily newspaper le monde (Score: 0.0118)\n",
      "- le monde daily newspaper (Score: 0.0118)\n",
      "- basque daily newspaper (Score: 0.0116)\n",
      "- basque weekly newspaper (Score: 0.0112)\n",
      "- online hate speech (Score: 0.0108)\n",
      "- popular online social network (Score: 0.0106)\n",
      "- national association (Score: 0.0105)\n",
      "- bilingual turkish-armenian weekly newspaper (Score: 0.0105)\n",
      "- online news articles (Score: 0.0105)\n",
      "- well-known turkish muslim theologian (Score: 0.0104)\n",
      "- public speech (Score: 0.0102)\n",
      "- specific ethnic group (Score: 0.0102)\n",
      "- national front (Score: 0.0102)\n",
      "- istanbul public prosecutor (Score: 0.0100)\n",
      "- public insult (Score: 0.0100)\n",
      "- public official (Score: 0.0100)\n",
      "- public order (Score: 0.0099)\n",
      "- national hatred (Score: 0.0098)\n",
      "- offensive online comments (Score: 0.0097)\n",
      "- public insults (Score: 0.0096)\n",
      "- national identity (Score: 0.0095)\n",
      "- national flag (Score: 0.0095)\n",
      "\n",
      "Keyphrases for access to internet factsheet - facts.docx:\n",
      "- certain internet sites (Score: 0.0503)\n",
      "- internet sites (Score: 0.0390)\n",
      "- own internet site (Score: 0.0361)\n",
      "- applicant internet access (Score: 0.0360)\n",
      "- internet websites (Score: 0.0321)\n",
      "- turkish constitutional court (Score: 0.0309)\n",
      "- information technology directorate (Score: 0.0287)\n",
      "- entire wikipedia website (Score: 0.0284)\n",
      "- internet access (Score: 0.0284)\n",
      "- internet site (Score: 0.0284)\n",
      "- legal information (Score: 0.0277)\n",
      "- internet (Score: 0.0244)\n",
      "- court proceedings (Score: 0.0235)\n",
      "- constitutional court (Score: 0.0229)\n",
      "- illegal armed organisation (Score: 0.0221)\n",
      "- mehmet reşit arslan (Score: 0.0221)\n",
      "- witnesses religious organisations (Score: 0.0221)\n",
      "- entire website (Score: 0.0212)\n",
      "- education-related information (Score: 0.0201)\n",
      "- educational information (Score: 0.0201)\n",
      "- european court (Score: 0.0195)\n",
      "- court decision (Score: 0.0195)\n",
      "- several sites (Score: 0.0190)\n",
      "- other sites (Score: 0.0190)\n",
      "- google sites (Score: 0.0190)\n",
      "- international website (Score: 0.0182)\n",
      "- whole website (Score: 0.0182)\n",
      "- legal ban (Score: 0.0167)\n",
      "- legal research (Score: 0.0167)\n",
      "- turkish law (Score: 0.0166)\n"
     ]
    }
   ],
   "source": [
    "import pke\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "def extract_keywords_textrank(documents_with_names, top_n=30):\n",
    "    \"\"\"Extract keywords using TextRank for each document.\"\"\"\n",
    "    keyphrases_by_document = []\n",
    "    \n",
    "    # Load stop words for English\n",
    "    stoplist = stopwords.words('english')\n",
    "    \n",
    "    for file_name, doc in documents_with_names:\n",
    "        # Initialize the TextRank extractor\n",
    "        extractor = pke.unsupervised.TextRank()\n",
    "        \n",
    "        # Load the document content with stop words applied\n",
    "        extractor.load_document(input=doc, language='en', normalization='lower', stoplist=stoplist)\n",
    "        \n",
    "        # Candidate selection: Use words as keyphrase candidates\n",
    "        extractor.candidate_selection(pos={'NOUN', 'PROPN', 'ADJ'})  # Focus on nouns, proper nouns, adjectives\n",
    "        \n",
    "        # Weight candidates using the TextRank algorithm\n",
    "        extractor.candidate_weighting(window=2)\n",
    "        \n",
    "        # Extract top N keyphrases\n",
    "        keyphrases = extractor.get_n_best(n=top_n)\n",
    "        keyphrases_by_document.append((file_name, keyphrases))\n",
    "    \n",
    "    return keyphrases_by_document\n",
    "\n",
    "# Extract keyphrases\n",
    "keyphrases_by_document = extract_keywords_textrank(documents_with_names, top_n=30)\n",
    "\n",
    "# Display results\n",
    "for file_name, keyphrases in keyphrases_by_document:\n",
    "    print(f\"\\nKeyphrases for {file_name}:\")\n",
    "    for phrase, score in keyphrases:\n",
    "        print(f\"- {phrase} (Score: {score:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d31c16-8a79-48fd-a2ee-6ab1d52eb64e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
